import streamlit as st
import re
import nltk
from spellchecker import SpellChecker
from nltk.tokenize import word_tokenize
from nltk.tokenize.treebank import TreebankWordDetokenizer

# ============== NLTK & SpellChecker Setup ==============
def load_resources():
    """NLTK ë°ì´í„°ì™€ SpellCheckerë¥¼ í•œ ë²ˆë§Œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        nltk.download('punkt', quiet=True)
    
    spell = SpellChecker(language='en')
    return spell

spell_checker = load_resources()

# ============== Logic from spelling_counter.py ==============
def tokenize_text(text: str):
    return word_tokenize(text)

def is_candidate_word(tok: str) -> bool:
    if not isinstance(tok, str):
        return False
    # ì•ŒíŒŒë²³ê³¼ ë”°ì˜´í‘œë§Œ í—ˆìš©
    if not re.match(r"^[A-Za-z']+$", tok):
        return False
    # 2ê¸€ì ì´í•˜ ì œì™¸
    if len(tok) <= 2:
        return False
    # ì „ì²´ ëŒ€ë¬¸ì(ì•½ì–´ ë“±) ì œì™¸
    if tok.isupper():
        return False
    return True

def analyze_and_correct(text: str, spell: SpellChecker):
    """
    í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ êµì •ëœ í…ìŠ¤íŠ¸ì™€ ì—ëŸ¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    detok = TreebankWordDetokenizer()
    tokens = tokenize_text(text)
    
    candidate_indices = [i for i, t in enumerate(tokens) if is_candidate_word(t)]
    candidate_words = [tokens[i].lower() for i in candidate_indices]
    
    # í•œ ë²ˆì— ì˜¤íƒ€ ì°¾ê¸°
    misspelled = spell.unknown(candidate_words)
    
    corrections_log = {}
    error_count = 0
    
    # êµì • ë¡œì§
    for i, lw in zip(candidate_indices, candidate_words):
        if lw in misspelled:
            orig = tokens[i]
            suggestion = spell.correction(lw)
            
            if not suggestion:
                continue
                
            # ë¡œê·¸ ì €ì¥
            if orig not in corrections_log:
                corrections_log[orig] = suggestion
                error_count += 1
            
            # ëŒ€ì†Œë¬¸ì ë³´ì¡´ ì²˜ë¦¬
            if orig.istitle():
                suggestion = suggestion.capitalize()
            elif orig.isupper():
                suggestion = suggestion.upper()
                
            tokens[i] = suggestion
            
    corrected_text = detok.detokenize(tokens)
    return corrected_text, corrections_log, error_count

# ============== ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ==============
def generate_spelling_response(text):
    corrected_text, corrections, count = analyze_and_correct(text, spell_checker)
    
    response_md = ""
    
    if count == 0:
        response_md += "**ì˜¤íƒ€ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**\n\nì™„ë²½í•œ ë¬¸ì¥ì´ë„¤ìš”!"
    else:
        response_md += f"ğŸ” **ì´ {count}ê°œì˜ ì˜¤íƒ€ë¥¼ ë°œê²¬í•˜ì—¬ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.**\n\n"
        response_md += "---\n"
        response_md += "**ìˆ˜ì •ëœ ë¬¸ì¥:**\n"
        response_md += f"> {corrected_text}\n\n"
        response_md += "---\n"
        response_md += "**ìƒì„¸ ìˆ˜ì • ë‚´ì—­:**\n"
        for original, fixed in corrections.items():
            response_md += f"- `{original}` â†’ **{fixed}**\n"
            
    return response_md